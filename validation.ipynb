{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:513: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:521: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object:\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool:\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:22: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/h5py/__init__.py:46: DeprecationWarning: `np.typeDict` is a deprecated alias for `np.sctypeDict`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:23: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  'nearest': pil_image.NEAREST,\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:24: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  'bilinear': pil_image.BILINEAR,\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:25: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  'bicubic': pil_image.BICUBIC,\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:28: DeprecationWarning: HAMMING is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.HAMMING instead.\n",
      "  if hasattr(pil_image, 'HAMMING'):\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:30: DeprecationWarning: BOX is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BOX instead.\n",
      "  if hasattr(pil_image, 'BOX'):\n",
      "/home/garrett/miniconda3/envs/cyborg/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:33: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  if hasattr(pil_image, 'LANCZOS'):\n"
     ]
    }
   ],
   "source": [
    "from environments import build_blue_agent, build_red_agent, sample\n",
    "\n",
    "import ray\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Dedicated Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ray\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "red = build_red_agent(dedicated=True)\n",
    "\n",
    "red_scores = [[],[],[],[],[]]\n",
    "\n",
    "print(\"+--------------------+\")\n",
    "print(\"| Red Training Start |\")\n",
    "print(\"+--------------------+\")\n",
    "\n",
    "for g in range(1,5):\n",
    "    path_file = open(f\"./policies/red_dedicated_pool/dedicated_red_0/checkpoint_path\", \"r\")\n",
    "    red_restore_path = path_file.read()\n",
    "    path_file.close()\n",
    "    red.restore(red_restore_path)\n",
    "    \n",
    "    print()\n",
    "    print(\"+--------------------+\")\n",
    "    print(f\"| Red Policy {g} Start |\")\n",
    "    print(\"+--------------------+\")\n",
    "    print()\n",
    "\n",
    "    red_max = 0\n",
    "\n",
    "    for b in range(1, 101):\n",
    "        result = red.train()\n",
    "        red_score = result[\"sampler_results\"][\"episode_reward_mean\"]\n",
    "        print(f'Red Score for Batch {b}: {red_score:0.2f}')\n",
    "        red_scores[g].append(red_score)\n",
    "        if red_score > red_max:\n",
    "            red_max = red_score\n",
    "            checkpoint_path = red.save(checkpoint_dir=f\"./policies/red_dedicated_pool/dedicated_red_{g}\")\n",
    "            path_file = open(f\"./policies/red_dedicated_pool/dedicated_red_{g}/checkpoint_path\", \"w\")\n",
    "            path_file.write(checkpoint_path)\n",
    "            path_file.close()\n",
    "    print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dedicated agent that achieved the best score\n",
    "r_max = 0\n",
    "r_id = 0\n",
    "for g in range(1,5):\n",
    "    if max(red_scores[g]) > r_max:\n",
    "        r_max = max(red_scores[g])\n",
    "        r_id = g\n",
    "print()\n",
    "print(f'Dedicated Red Agent {r_id} reached the highest score.')\n",
    "\n",
    "path_file = open(f\"./policies/red_pool/dedicated_red_{r_id}/checkpoint_path\", \"r\")\n",
    "dedicated_red_path = path_file.read()\n",
    "path_file.close()\n",
    "path_file = open(f\"./policies/dedicated_red_policy\", \"w\")\n",
    "path_file.write(dedicated_red_path)\n",
    "path_file.close()\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Ray\n",
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "blue = build_blue_agent(dedicated=True)\n",
    "\n",
    "blue_scores = [[],[],[],[],[]]\n",
    "\n",
    "print()\n",
    "print(\"+---------------------+\")\n",
    "print(\"| Blue Training Start |\")\n",
    "print(\"+---------------------+\")\n",
    "print()\n",
    "\n",
    "for g in range(1,5):\n",
    "    path_file = open(f\"./policies/blue_dedicated_pool/dedicated_blue_0/checkpoint_path\", \"r\")\n",
    "    blue_restore_path = path_file.read()\n",
    "    path_file.close()\n",
    "    blue.restore(blue_restore_path)\n",
    "\n",
    "    print()\n",
    "    print(\"+---------------------+\")\n",
    "    print(f\"| Blue Policy {g} Start |\")\n",
    "    print(\"+---------------------+\")\n",
    "    print()\n",
    "\n",
    "    for b in range(1, 101):\n",
    "        result = blue.train()\n",
    "        blue_score = -result[\"sampler_results\"][\"episode_reward_mean\"]\n",
    "        print(f'Blue Score for Batch {b}: {blue_score:0.2f}')\n",
    "        blue_scores[g].append(blue_score)\n",
    "    checkpoint_path = blue.save(checkpoint_dir=f\"./policies/blue_dedicated_pool/dedicated_blue_{g}\")\n",
    "    path_file = open(f\"./policies/blue_dedicated_pool/dedicated_blue_{g}/checkpoint_path\", \"w\")\n",
    "    path_file.write(checkpoint_path)\n",
    "    path_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find dedicated agents that achieved the best scores\n",
    "b_min = float('inf')\n",
    "b_id = 0\n",
    "\n",
    "for g in range(1,5):\n",
    "    if min(blue_scores[g]) < b_min:\n",
    "        b_min = min(blue_scores[g])\n",
    "        b_id = g\n",
    "\n",
    "print()\n",
    "print(f'Dedicated Blue Agent {b_id} reached the lowest score.')\n",
    "\n",
    "path_file = open(f\"./policies/blue_pool/dedicated_blue_{b_id}/checkpoint_path\", \"r\")\n",
    "dedicated_blue_path = path_file.read()\n",
    "path_file.close()\n",
    "path_file = open(f\"./policies/dedicated_blue_policy\", \"w\")\n",
    "path_file.write(dedicated_blue_path)\n",
    "path_file.close()\n",
    "\n",
    "ray.shutdown()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores During Training\n",
    "id_plot = [id for id in range(1,101)]\n",
    "for g in range(1,5):\n",
    "    print(f'Dedicated Red Agent {g}')\n",
    "    data_plot = pd.DataFrame({\"Iteration\":id_plot, \"Training Score\":red_scores[g]})\n",
    "    plt.figure()\n",
    "    sns.lineplot(x = \"Iteration\", y = \"Training Score\", data=data_plot, color='red')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_plot = [id for id in range(1,101)]\n",
    "for g in range(1,5):\n",
    "    print(f'Dedicated Blue Agent {g}')\n",
    "    data_plot = pd.DataFrame({\"Iteration\":id_plot, \"Training Score\":blue_scores[g]})\n",
    "    plt.figure()\n",
    "    sns.lineplot(x = \"Iteration\", y = \"Training Score\", data=data_plot, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Game Between Competitive Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(ignore_reinit_error=True, log_to_driver=False)\n",
    "\n",
    "red = build_red_agent(workers=1, fresh=False)\n",
    "blue = build_blue_agent(workers=1, fresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = open(f\"./policies/competitive_blue_policy\", \"r\")\n",
    "blue_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "blue.restore(blue_restore_path)\n",
    "\n",
    "path_file = open(f\"./policies/competitive_red_policy\", \"r\")\n",
    "red_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "red.restore(red_restore_path)\n",
    "\n",
    "sample(red, blue, verbose=True, show_policy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Game between Competitive Blue and Dedicated Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = build_red_agent(dedicated=True, workers=1, fresh=False)\n",
    "blue = build_blue_agent(workers=1, fresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = open(f\"./policies/competitive_blue_policy\", \"r\")\n",
    "blue_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "blue.restore(blue_restore_path)\n",
    "\n",
    "path_file = open(f\"./policies/dedicated_red_policy\", \"r\")\n",
    "red_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "red.restore(red_restore_path)\n",
    "\n",
    "sample(red, blue, verbose=True, show_policy=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Game between Dedicated Blue and Competitive Red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = build_red_agent(workers=1, fresh=False)\n",
    "blue = build_blue_agent(dedicated=True, workers=1, fresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = open(f\"./policies/dedicated_blue_policy\", \"r\")\n",
    "blue_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "blue.restore(blue_restore_path)\n",
    "\n",
    "path_file = open(f\"./policies/competitive_red_policy\", \"r\")\n",
    "red_restore_path = path_file.read()\n",
    "path_file.close()\n",
    "red.restore(red_restore_path)\n",
    "\n",
    "sample(red, blue, verbose=True, show_policy=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyborg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ad09acfcbc77eceeff7dacd928eeb00a75d739c56abde2050ff4da463580de0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
